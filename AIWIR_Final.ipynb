{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Custom Support Twitter "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By:  \n",
        "PES2UG20CS009 Abhay R Warrier  \n",
        "PES2UG20CS134 Harsha Pai  \n",
        "PES2UG20CS174 Kunal E  \n",
        "PES2UG20CS175 Kuval Kush Garg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1_q8hEKjZtjF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('twcs.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "j0IazMByZtjL",
        "outputId": "75533c67-e738-4a79-ead0-8f35f4a31212"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
              "      <td>@115712 I understand. I would like to assist y...</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
              "      <td>@sprintcare and how do you propose we do that</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
              "      <td>@sprintcare I have sent several private messag...</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
              "      <td>@115712 Please send us a Private Message so th...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
              "      <td>@sprintcare I did.</td>\n",
              "      <td>4</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811769</th>\n",
              "      <td>2987947</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Wed Nov 22 08:43:51 +0000 2017</td>\n",
              "      <td>@823869 Hey, we'd be happy to look into this f...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2987948.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811770</th>\n",
              "      <td>2987948</td>\n",
              "      <td>823869</td>\n",
              "      <td>True</td>\n",
              "      <td>Wed Nov 22 08:35:16 +0000 2017</td>\n",
              "      <td>@115714 wtf!? I’ve been having really shitty s...</td>\n",
              "      <td>2987947</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811771</th>\n",
              "      <td>2812240</td>\n",
              "      <td>121673</td>\n",
              "      <td>True</td>\n",
              "      <td>Thu Nov 23 04:13:07 +0000 2017</td>\n",
              "      <td>@143549 @sprintcare You have to go to https://...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2812239.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811772</th>\n",
              "      <td>2987949</td>\n",
              "      <td>AldiUK</td>\n",
              "      <td>False</td>\n",
              "      <td>Wed Nov 22 08:31:24 +0000 2017</td>\n",
              "      <td>@823870 Sounds delicious, Sarah! 😋 https://t.c...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2987950.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811773</th>\n",
              "      <td>2987950</td>\n",
              "      <td>823870</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Nov 21 22:01:04 +0000 2017</td>\n",
              "      <td>@AldiUK  warm sloe gin mince pies with ice cre...</td>\n",
              "      <td>2987951,2987949</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2811774 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         tweet_id   author_id  inbound                      created_at  \\\n",
              "0               1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
              "1               2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
              "2               3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
              "3               4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
              "4               5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
              "...           ...         ...      ...                             ...   \n",
              "2811769   2987947  sprintcare    False  Wed Nov 22 08:43:51 +0000 2017   \n",
              "2811770   2987948      823869     True  Wed Nov 22 08:35:16 +0000 2017   \n",
              "2811771   2812240      121673     True  Thu Nov 23 04:13:07 +0000 2017   \n",
              "2811772   2987949      AldiUK    False  Wed Nov 22 08:31:24 +0000 2017   \n",
              "2811773   2987950      823870     True  Tue Nov 21 22:01:04 +0000 2017   \n",
              "\n",
              "                                                      text response_tweet_id  \\\n",
              "0        @115712 I understand. I would like to assist y...                 2   \n",
              "1            @sprintcare and how do you propose we do that               NaN   \n",
              "2        @sprintcare I have sent several private messag...                 1   \n",
              "3        @115712 Please send us a Private Message so th...                 3   \n",
              "4                                       @sprintcare I did.                 4   \n",
              "...                                                    ...               ...   \n",
              "2811769  @823869 Hey, we'd be happy to look into this f...               NaN   \n",
              "2811770  @115714 wtf!? I’ve been having really shitty s...           2987947   \n",
              "2811771  @143549 @sprintcare You have to go to https://...               NaN   \n",
              "2811772  @823870 Sounds delicious, Sarah! 😋 https://t.c...               NaN   \n",
              "2811773  @AldiUK  warm sloe gin mince pies with ice cre...   2987951,2987949   \n",
              "\n",
              "         in_response_to_tweet_id  \n",
              "0                            3.0  \n",
              "1                            1.0  \n",
              "2                            4.0  \n",
              "3                            5.0  \n",
              "4                            6.0  \n",
              "...                          ...  \n",
              "2811769                2987948.0  \n",
              "2811770                      NaN  \n",
              "2811771                2812239.0  \n",
              "2811772                2987950.0  \n",
              "2811773                      NaN  \n",
              "\n",
              "[2811774 rows x 7 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExxBJhetZtjQ",
        "outputId": "497cb7b1-60e4-4d32-ddf2-adbf778940c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2811774 entries, 0 to 2811773\n",
            "Data columns (total 7 columns):\n",
            " #   Column                   Dtype  \n",
            "---  ------                   -----  \n",
            " 0   tweet_id                 int64  \n",
            " 1   author_id                object \n",
            " 2   inbound                  bool   \n",
            " 3   created_at               object \n",
            " 4   text                     object \n",
            " 5   response_tweet_id        object \n",
            " 6   in_response_to_tweet_id  float64\n",
            "dtypes: bool(1), float64(1), int64(1), object(4)\n",
            "memory usage: 131.4+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVowpqrRZtjS",
        "outputId": "a0af220c-6bb0-42e5-c085-5a05cf6fbf47"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\abhay\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\abhay\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\abhay\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Omf4ooztZtjV"
      },
      "outputs": [],
      "source": [
        "df[\"text\"] = df[\"text\"].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wDJ_T4iZtjW",
        "outputId": "a8eff45e-fa3f-44d9-801a-7138bdeffb06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0     @115712 i understand. i would like to assist y...\n",
            "1         @sprintcare and how do you propose we do that\n",
            "2     @sprintcare i have sent several private messag...\n",
            "3     @115712 please send us a private message so th...\n",
            "4                                    @sprintcare i did.\n",
            "                            ...                        \n",
            "95    considering walking to @chipotletweets in my l...\n",
            "96    @115742 i love it! thanks so much for stopping...\n",
            "97    @chipotletweets name a better halloween duo #s...\n",
            "98    @115743 there is no info to share at the momen...\n",
            "99     @askplaystation @115743 can i get help already??\n",
            "Name: text, Length: 100, dtype: object\n"
          ]
        }
      ],
      "source": [
        "#Doing only for 100 records\n",
        "text = df['text'].head(100)\n",
        "originalText = text\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-NqY6w5ZtjX",
        "outputId": "46324cf3-b1c6-4810-9c82-9c32de15ab24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['@115712 i understand.', 'i would like to assist you.', 'we would need to get you into a private secured link to further assist.']\n",
            "['@sprintcare and how do you propose we do that']\n",
            "['@sprintcare i have sent several private messages and no one is responding as usual']\n",
            "['@115712 please send us a private message so that we can further assist you.', 'just click ‘message’ at the top of your profile.']\n",
            "['@sprintcare i did.']\n",
            "['@115712 can you please send us a private message, so that i can gain further details about your account?']\n",
            "['@sprintcare is the worst customer service']\n",
            "['@115713 this is saddening to hear.', 'please shoot us a dm, so that we can look into this for you.', '-kc']\n",
            "['@sprintcare you gonna magically change your connectivity for me and my whole family ?', '🤥 💯']\n",
            "[\"@115713 we understand your concerns and we'd like for you to please send us a direct message, so that we can further assist you.\", '-aa']\n",
            "['@sprintcare since i signed up with you....since day 1']\n",
            "['@115713 h there!', \"we'd definitely like to work with you on this, how long have you been experiencing this issue?\", '-aa']\n",
            "['@115714 y’all lie about your “great” connection.', '5 bars lte, still won’t load something.', 'smh.']\n",
            "['@115715 please send me a private message so that i can send you the link to access your account.', '-fr']\n",
            "[\"@115714 whenever i contact customer support, they tell me i have shortcode enabled on my account, but i have never in the 4 years i've tried https://t.co/0g98rtnxpk\"]\n",
            "['@115716 what information is incorrect?', '^jk']\n",
            "['@ask_spectrum would you like me to email you a copy of one since spectrum is not updating your training?']\n",
            "['@115716 our department is part of the corporate office.', \"if you're particular area has gone to this format, we were unawa... https://t.co/p7xcmtzpqj\"]\n",
            "['@ask_spectrum i received this from your corporate office would you like a copy?']\n",
            "['@115716 no thank you.', '^jk']\n",
            "['@ask_spectrum the correct way to do it is via an ocs account takeover and email consent form it does not need to be done in a local office']\n",
            "['@ask_spectrum that is incorrect information i have the form in front of me that is faxed over-maybe you need to maintain up to date information']\n",
            "['@115716 the information pertaining to the account assumption is correct.', 'this does need to be done at a local outlet wit... https://t.co/p7xcmtzpqj']\n",
            "[\"actually that's a broken link you sent me and incorrect information https://t.co/v4yfrhr8vi\"]\n",
            "['@115717 hello, my apologies for any frustrations or inconvenience.', 'i’d be happy to look into this for you?', '^mg']\n",
            "['yo @ask_spectrum, your customer service reps are super nice— but imma start trippin if y’all don’t get my service going!']\n",
            "['@115718 i apologize for the inconvenience.', 'i will be glad to assist you.', 'can you dm me your name and acct # or phone #?', '-jb']\n",
            "['my picture on @ask_spectrum pretty much every day.', 'why should i pay $171 per month?', 'https://t.co/u6ptkqa5ik']\n",
            "['@115719 help has arrived!', 'we are sorry to see that you are having trouble.', 'how can we help?', '^hsb']\n",
            "['@verizonsupport i finally got someone that helped me, thanks!']\n",
            "['@115719 awesome!', 'if you ever need us we are just a tweet away.', '^hsb']\n",
            "[\"somebody from @verizonsupport please help meeeeee 😩😩😩😩 i'm having the worst luck with your customer service\"]\n",
            "['@115720 have your friend message us.', '^acm']\n",
            "['@verizonsupport my friend is without internet we need to play videogames together please our skills diminish every moment without internetz']\n",
            "['@115721 please follow and dm us so that we can look into this order.', '^hsb']\n",
            "['@verizonsupport what else can i provide?', 'they refuse to help me because they cannot validate the account...']\n",
            "['@115721 we would not be able to verify anything without authenticating your account.', '^jay']\n",
            "['@verizonsupport how?', \"i have my phone number and email, that's it.\", 'how did i get equipment and service?', \"i'm literally trying to pay and nobody can find me?\"]\n",
            "['@115721 we can use the order number to locate the account but will need to do so in our secure one on one chat.', 'please follow and dm us.', '^hsb']\n",
            "['@115722 md.', 'and this was sent to the wrong address https://t.co/dmq1wzxjok']\n",
            "['@115721 hello duke, do you have a copy of your bill?', 'what state are your services located in?', '^nhp']\n",
            "['@115722 nobody can find my account or number.', 'i walked out of a store with this.', \"i've explained that they can find my acct via my devices serial #..\"]\n",
            "['@115721 are you referring to wireless or residential service?', '^jay']\n",
            "['@115722 tried to pay a bill for 60 days.', 'no service, rude cs, and several transfers.', 'look up my equipment # and give me an acct #!']\n",
            "['@115723 is the light on top red?', '^jay']\n",
            "['@verizonsupport don’t know, router is downstairs.', 'but it’s just the wifi nothing connected to ethernet']\n",
            "['@115723 did the lights change on the router when this happened?', '^jay']\n",
            "['@verizonsupport just randomly boots me offline there it goes again']\n",
            "['@115723 do you have our fios service?', 'when services go out, does the internet light on the router change color?', '^bcw']\n",
            "['@verizonsupport yep']\n",
            "['@115723 are all your services cutting out?', '^acm']\n",
            "['@verizonsupport cuts out every 20 minutes this is ridiculous']\n",
            "['@115723 what did we do to make you feel this way and how can we fix things between us?', '^kmg']\n",
            "['@115722 is the worst isp i’ve ever had']\n",
            "['@115724 in what area are you located?', 'all of your services are down at this time?', '^hsb']\n",
            "['.', '@verizonsupport @115725 @115726                                                 &gt;all of verizon is down&lt;\\nwhen can we expect a fix ?']\n",
            "['@115727 which app are you referring too?', '^acm']\n",
            "[\"@115725 fix your app it won't even open\"]\n",
            "['@115728 i still think you look great!', '-becky']\n",
            "['@chipotletweets @chipotletweets becky is very nice']\n",
            "[\"@chipotletweets @28 \\ni don't fit in my veggie burrito costume #halloween https://t.co/7tjdvpzlwn\"]\n",
            "[\"@115729 i'm so sorry about that.\", 'please tell us more so we can help: https://t.co/ax7w1dx3y9 -becky']\n",
            "['@chipotletweets messed up today and didn’t give me my $3 burrito although i was dressed up 😭']\n",
            "[\"@115730 hopefully we'll get there at some point!\", '-becky']\n",
            "['hey @chipotletweets wanna come to mammoth.', \"i'll at least eat there once a week i promise\"]\n",
            "['@115731 guac on!', \"i'm happy it was such a great experience.\", '-becky']\n",
            "['@chipotletweets i had excellent service tonight too!', 'plenty of people on the line, went very fast, everyone was kind!']\n",
            "[\"@115731 it's because you're smart.\", '-tara']\n",
            "[\"when you're the only one in costume #boorito @chipotletweets\"]\n",
            "[\"@115732 that's incredibly concerning.\", 'please tell us more here: https://t.co/ax7w1dx3y9 -becky']\n",
            "['@chipotletweets no diet coke and a literal bone this boorito was extra spooky!', 'https://t.co/c4occtduct']\n",
            "['@115733 nope!', 'still just the $3.', '-becky']\n",
            "[\"@chipotletweets if you get queso or quac on you're bowl, its extra?\"]\n",
            "['just stop by in costume 10/31 3pm-close.', 'official rules: https://t.co/1hmw7qxweh https://t.co/wn0xerxc2z']\n",
            "['@115734 i mean, boorito is basically the adult version of halloween... -becky']\n",
            "['happy halloween!', \"since i'm too old to trick or treat i now look forward to $3 booritos at @chipotletweets 👻 i got mine earlier, did you?\"]\n",
            "[\"@115735 i'm so glad we could help.\", 'who did you work with?', \"i'd like to share the praise.\", '-becky']\n",
            "['@chipotletweets thank you @chipotletweets for resolving my issue so quickly!!', 'y’all are the best ☺️ #fanforlife']\n",
            "['so frustrated with @chipotletweets 😡 ordered dinner on saturday using their app.', 'order was wrong and they charged my credit card twice']\n",
            "['@115736 all of our u.s. locations are participating!', '-becky']\n",
            "['btw @chipotletweets giving out $3 burritos if you dress up for halloween 🎃 call your chipotle to make sure, they’re doing it @ select ones']\n",
            "['@115737 my apologies for that.', 'just sent you a dm to help.', '-becky']\n",
            "[\"@chipotletweets tried, didn't work.\", 'how rude :/']\n",
            "['@115737 give it a try.', '-tara']\n",
            "['@chipotletweets can i dress up as myself and still qualify for a boorito?']\n",
            "[\"@115738 that's the best kind of trick-or-treating.\", 'all treats, my friend.', '-becky']\n",
            "['every year, my trick-or-treating routine is walking to chipotle, spending 3 dollars and walking back home.', '@chipotletweets']\n",
            "[\"@115739 that's incredibly concerning.\", 'please provide more details so we can investigate: https://t.co/ax7w1dx3y9 -becky']\n",
            "['@chipotletweets this is nasty.', \"a used napkin in someone's food https://t.co/ekwid9vhnr\"]\n",
            "['@115740 bummer.', \"i'm so sorry.\", 'how far away is the closest location?', '-becky']\n",
            "['$3 burritos and i’m nowhere near a @chipotletweets 🤦🏾\\u200d♂️']\n",
            "['@115741 noted 😊 -becky']\n",
            "['@chipotletweets also i got the onesie at target.', 'so cozy']\n",
            "['@chipotletweets thanks becky!', 'just feeling sorry for myself because my fiancé is driving from d.c. to mississippi tonight']\n",
            "[\"@115741 you won't be alone – we'll be there with you.\", 'also, i want that llama onesie.', '-becky']\n",
            "['considering walking to @chipotletweets in my llama onesie alone happy halloween 😭']\n",
            "['@115742 i love it!', 'thanks so much for stopping by.', '-becky']\n",
            "['@chipotletweets name a better halloween duo #speedwaybrick #uttranscript https://t.co/5shdrmlc1t']\n",
            "['@115743 there is no info to share at the moment.', 'feel free to keep an eye on the ps blog for news and updates: https://t.co/altfbaztyc']\n",
            "['@askplaystation @115743 can i get help already?', '?']\n"
          ]
        }
      ],
      "source": [
        "for i in text:\n",
        "    print(sent_tokenize(i))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PRE PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NvLv2ssjZtjZ"
      },
      "outputs": [],
      "source": [
        "#Using RegEx\n",
        "Cond1 = r'@[A-Za-z0-9]+' \n",
        "Cond2 = r'https?://[A-Za-z0-9./]+'  \n",
        "combined_Cond = r'|'.join((Cond1, Cond2)) \n",
        "Cond3 = r'[^a-zA-Z0-9]' \n",
        "finalCombinedCond = r'|'.join((combined_Cond,Cond3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdkOMn00Ztja",
        "outputId": "c6c27e73-c244-462c-acf7-644119bfaa58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['understand would like assist would need get private secured link assist',\n",
              " 'propose',\n",
              " 'sent several private messages one responding usual',\n",
              " 'please send us private message assist click message top profile',\n",
              " '',\n",
              " 'please send us private message gain details account',\n",
              " 'worst customer service',\n",
              " 'saddening hear please shoot us dm look kc',\n",
              " 'gon na magically change connectivity whole family',\n",
              " 'understand concerns like please send us direct message assist aa',\n",
              " 'since signed since day 1',\n",
              " 'h definitely like work long experiencing issue aa',\n",
              " 'lie great connection 5 bars lte still load something smh',\n",
              " 'please send private message send link access account fr',\n",
              " 'whenever contact customer support tell shortcode enabled account never 4 years tried',\n",
              " 'information incorrect jk',\n",
              " 'spectrum would like email copy one since spectrum updating training',\n",
              " 'department part corporate office particular area gone format unawa',\n",
              " 'spectrum received corporate office would like copy',\n",
              " 'thank jk',\n",
              " 'spectrum correct way via ocs account takeover email consent form need done local office',\n",
              " 'spectrum incorrect information form front faxed maybe need maintain date information',\n",
              " 'information pertaining account assumption correct need done local outlet wit',\n",
              " 'actually broken link sent incorrect information',\n",
              " 'hello apologies frustrations inconvenience happy look mg',\n",
              " 'yo spectrum customer service reps super nice imma start trippin get service going',\n",
              " 'apologize inconvenience glad assist dm name acct phone jb',\n",
              " 'picture spectrum pretty much every day pay 171 per month',\n",
              " 'help arrived sorry see trouble help hsb',\n",
              " 'finally got someone helped thanks',\n",
              " 'awesome ever need us tweet away hsb',\n",
              " 'somebody please help meeeeee worst luck customer service',\n",
              " 'friend message us acm',\n",
              " 'friend without internet need play videogames together please skills diminish every moment without internetz',\n",
              " 'please follow dm us look order hsb',\n",
              " 'else provide refuse help validate account',\n",
              " 'would able verify anything without authenticating account jay',\n",
              " 'phone number email get equipment service literally trying pay nobody find',\n",
              " 'use order number locate account need secure one one chat please follow dm us hsb',\n",
              " 'md sent wrong address',\n",
              " 'hello duke copy bill state services located nhp',\n",
              " 'nobody find account number walked store explained find acct via devices serial',\n",
              " 'referring wireless residential service jay',\n",
              " 'tried pay bill 60 days service rude cs several transfers look equipment give acct',\n",
              " 'light top red jay',\n",
              " 'know router downstairs wifi nothing connected ethernet',\n",
              " 'lights change router happened jay',\n",
              " 'randomly boots offline goes',\n",
              " 'fios service services go internet light router change color bcw',\n",
              " 'yep',\n",
              " 'services cutting acm',\n",
              " 'cuts every 20 minutes ridiculous',\n",
              " 'make feel way fix things us kmg',\n",
              " 'worst isp ever',\n",
              " 'area located services time hsb',\n",
              " 'gt verizon lt expect fix',\n",
              " 'app referring acm',\n",
              " 'fix app even open',\n",
              " 'still think look great becky',\n",
              " 'becky nice',\n",
              " 'fit veggie burrito costume halloween',\n",
              " 'sorry please tell us help becky',\n",
              " 'messed today give 3 burrito although dressed',\n",
              " 'hopefully get point becky',\n",
              " 'hey wan na come mammoth least eat week promise',\n",
              " 'guac happy great experience becky',\n",
              " 'excellent service tonight plenty people line went fast everyone kind',\n",
              " 'smart tara',\n",
              " 'one costume boorito',\n",
              " 'incredibly concerning please tell us becky',\n",
              " 'diet coke literal bone boorito extra spooky',\n",
              " 'nope still 3 becky',\n",
              " 'get queso quac bowl extra',\n",
              " 'stop costume 10 31 3pm close official rules',\n",
              " 'mean boorito basically adult version halloween becky',\n",
              " 'happy halloween since old trick treat look forward 3 booritos got mine earlier',\n",
              " 'glad could help work like share praise becky',\n",
              " 'thank resolving issue quickly best fanforlife',\n",
              " 'frustrated ordered dinner saturday using app order wrong charged credit card twice',\n",
              " 'u locations participating becky',\n",
              " 'btw giving 3 burritos dress halloween call chipotle make sure select ones',\n",
              " 'apologies sent dm help becky',\n",
              " 'tried work rude',\n",
              " 'give try tara',\n",
              " 'dress still qualify boorito',\n",
              " 'best kind trick treating treats friend becky',\n",
              " 'every year trick treating routine walking chipotle spending 3 dollars walking back home',\n",
              " 'incredibly concerning please provide details investigate becky',\n",
              " 'nasty used napkin someone food',\n",
              " 'bummer sorry far away closest location becky',\n",
              " '3 burritos nowhere near',\n",
              " 'noted becky',\n",
              " 'also got onesie target cozy',\n",
              " 'thanks becky feeling sorry fianc driving c mississippi tonight',\n",
              " 'alone also want llama onesie becky',\n",
              " 'considering walking llama onesie alone happy halloween',\n",
              " 'love thanks much stopping becky',\n",
              " 'name better halloween duo speedwaybrick uttranscript',\n",
              " 'info share moment feel free keep eye ps blog news updates',\n",
              " 'get help already']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_Sentence=[]\n",
        "for i in range(0, len(text)):\n",
        "    reviews = re.sub(finalCombinedCond,' ',text[i])\n",
        "    reviews = word_tokenize(reviews) #TOKENIZATION\n",
        "    reviews = [word for word in reviews if not word in set(stopwords.words('english'))] #STOPWORD REMOVAL\n",
        "    reviews = ' '.join(reviews)\n",
        "    filtered_Sentence.append(reviews)\n",
        "    \n",
        "filtered_Sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AazZ2xAzZtjc",
        "outputId": "62fa21ca-1dc2-49fb-fccd-1e1c8ce2f066"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['understand',\n",
              " 'would',\n",
              " 'like',\n",
              " 'assist',\n",
              " 'would',\n",
              " 'need',\n",
              " 'get',\n",
              " 'privat',\n",
              " 'secur',\n",
              " 'link',\n",
              " 'assist',\n",
              " 'propos',\n",
              " 'sent',\n",
              " 'sever',\n",
              " 'privat',\n",
              " 'messag',\n",
              " 'one',\n",
              " 'respond',\n",
              " 'usual',\n",
              " 'pleas',\n",
              " 'send',\n",
              " 'us',\n",
              " 'privat',\n",
              " 'messag',\n",
              " 'assist',\n",
              " 'click',\n",
              " 'messag',\n",
              " 'top',\n",
              " 'profil',\n",
              " 'pleas',\n",
              " 'send',\n",
              " 'us',\n",
              " 'privat',\n",
              " 'messag',\n",
              " 'gain',\n",
              " 'detail',\n",
              " 'account',\n",
              " 'worst',\n",
              " 'custom',\n",
              " 'servic',\n",
              " 'sadden',\n",
              " 'hear',\n",
              " 'pleas',\n",
              " 'shoot',\n",
              " 'us',\n",
              " 'dm',\n",
              " 'look',\n",
              " 'kc',\n",
              " 'gon',\n",
              " 'na',\n",
              " 'magic',\n",
              " 'chang',\n",
              " 'connect',\n",
              " 'whole',\n",
              " 'famili',\n",
              " 'understand',\n",
              " 'concern',\n",
              " 'like',\n",
              " 'pleas',\n",
              " 'send',\n",
              " 'us',\n",
              " 'direct',\n",
              " 'messag',\n",
              " 'assist',\n",
              " 'aa',\n",
              " 'sinc',\n",
              " 'sign',\n",
              " 'sinc',\n",
              " 'day',\n",
              " '1',\n",
              " 'h',\n",
              " 'definit',\n",
              " 'like',\n",
              " 'work',\n",
              " 'long',\n",
              " 'experienc',\n",
              " 'issu',\n",
              " 'aa',\n",
              " 'lie',\n",
              " 'great',\n",
              " 'connect',\n",
              " '5',\n",
              " 'bar',\n",
              " 'lte',\n",
              " 'still',\n",
              " 'load',\n",
              " 'someth',\n",
              " 'smh',\n",
              " 'pleas',\n",
              " 'send',\n",
              " 'privat',\n",
              " 'messag',\n",
              " 'send',\n",
              " 'link',\n",
              " 'access',\n",
              " 'account',\n",
              " 'fr',\n",
              " 'whenev',\n",
              " 'contact',\n",
              " 'custom',\n",
              " 'support',\n",
              " 'tell',\n",
              " 'shortcod',\n",
              " 'enabl',\n",
              " 'account',\n",
              " 'never',\n",
              " '4',\n",
              " 'year',\n",
              " 'tri',\n",
              " 'inform',\n",
              " 'incorrect',\n",
              " 'jk',\n",
              " 'spectrum',\n",
              " 'would',\n",
              " 'like',\n",
              " 'email',\n",
              " 'copi',\n",
              " 'one',\n",
              " 'sinc',\n",
              " 'spectrum',\n",
              " 'updat',\n",
              " 'train',\n",
              " 'depart',\n",
              " 'part',\n",
              " 'corpor',\n",
              " 'offic',\n",
              " 'particular',\n",
              " 'area',\n",
              " 'gone',\n",
              " 'format',\n",
              " 'unawa',\n",
              " 'spectrum',\n",
              " 'receiv',\n",
              " 'corpor',\n",
              " 'offic',\n",
              " 'would',\n",
              " 'like',\n",
              " 'copi',\n",
              " 'thank',\n",
              " 'jk',\n",
              " 'spectrum',\n",
              " 'correct',\n",
              " 'way',\n",
              " 'via',\n",
              " 'oc',\n",
              " 'account',\n",
              " 'takeov',\n",
              " 'email',\n",
              " 'consent',\n",
              " 'form',\n",
              " 'need',\n",
              " 'done',\n",
              " 'local',\n",
              " 'offic',\n",
              " 'spectrum',\n",
              " 'incorrect',\n",
              " 'inform',\n",
              " 'form',\n",
              " 'front',\n",
              " 'fax',\n",
              " 'mayb',\n",
              " 'need',\n",
              " 'maintain',\n",
              " 'date',\n",
              " 'inform',\n",
              " 'inform',\n",
              " 'pertain',\n",
              " 'account',\n",
              " 'assumpt',\n",
              " 'correct',\n",
              " 'need',\n",
              " 'done',\n",
              " 'local',\n",
              " 'outlet',\n",
              " 'wit',\n",
              " 'actual',\n",
              " 'broken',\n",
              " 'link',\n",
              " 'sent',\n",
              " 'incorrect',\n",
              " 'inform',\n",
              " 'hello',\n",
              " 'apolog',\n",
              " 'frustrat',\n",
              " 'inconveni',\n",
              " 'happi',\n",
              " 'look',\n",
              " 'mg',\n",
              " 'yo',\n",
              " 'spectrum',\n",
              " 'custom',\n",
              " 'servic',\n",
              " 'rep',\n",
              " 'super',\n",
              " 'nice',\n",
              " 'imma',\n",
              " 'start',\n",
              " 'trippin',\n",
              " 'get',\n",
              " 'servic',\n",
              " 'go',\n",
              " 'apolog',\n",
              " 'inconveni',\n",
              " 'glad',\n",
              " 'assist',\n",
              " 'dm',\n",
              " 'name',\n",
              " 'acct',\n",
              " 'phone',\n",
              " 'jb',\n",
              " 'pictur',\n",
              " 'spectrum',\n",
              " 'pretti',\n",
              " 'much',\n",
              " 'everi',\n",
              " 'day',\n",
              " 'pay',\n",
              " '171',\n",
              " 'per',\n",
              " 'month',\n",
              " 'help',\n",
              " 'arriv',\n",
              " 'sorri',\n",
              " 'see',\n",
              " 'troubl',\n",
              " 'help',\n",
              " 'hsb',\n",
              " 'final',\n",
              " 'got',\n",
              " 'someon',\n",
              " 'help',\n",
              " 'thank',\n",
              " 'awesom',\n",
              " 'ever',\n",
              " 'need',\n",
              " 'us',\n",
              " 'tweet',\n",
              " 'away',\n",
              " 'hsb',\n",
              " 'somebodi',\n",
              " 'pleas',\n",
              " 'help',\n",
              " 'meeeeee',\n",
              " 'worst',\n",
              " 'luck',\n",
              " 'custom',\n",
              " 'servic',\n",
              " 'friend',\n",
              " 'messag',\n",
              " 'us',\n",
              " 'acm',\n",
              " 'friend',\n",
              " 'without',\n",
              " 'internet',\n",
              " 'need',\n",
              " 'play',\n",
              " 'videogam',\n",
              " 'togeth',\n",
              " 'pleas',\n",
              " 'skill',\n",
              " 'diminish',\n",
              " 'everi',\n",
              " 'moment',\n",
              " 'without',\n",
              " 'internetz',\n",
              " 'pleas',\n",
              " 'follow',\n",
              " 'dm',\n",
              " 'us',\n",
              " 'look',\n",
              " 'order',\n",
              " 'hsb',\n",
              " 'els',\n",
              " 'provid',\n",
              " 'refus',\n",
              " 'help',\n",
              " 'valid',\n",
              " 'account',\n",
              " 'would',\n",
              " 'abl',\n",
              " 'verifi',\n",
              " 'anyth',\n",
              " 'without',\n",
              " 'authent',\n",
              " 'account',\n",
              " 'jay',\n",
              " 'phone',\n",
              " 'number',\n",
              " 'email',\n",
              " 'get',\n",
              " 'equip',\n",
              " 'servic',\n",
              " 'liter',\n",
              " 'tri',\n",
              " 'pay',\n",
              " 'nobodi',\n",
              " 'find',\n",
              " 'use',\n",
              " 'order',\n",
              " 'number',\n",
              " 'locat',\n",
              " 'account',\n",
              " 'need',\n",
              " 'secur',\n",
              " 'one',\n",
              " 'one',\n",
              " 'chat',\n",
              " 'pleas',\n",
              " 'follow',\n",
              " 'dm',\n",
              " 'us',\n",
              " 'hsb',\n",
              " 'md',\n",
              " 'sent',\n",
              " 'wrong',\n",
              " 'address',\n",
              " 'hello',\n",
              " 'duke',\n",
              " 'copi',\n",
              " 'bill',\n",
              " 'state',\n",
              " 'servic',\n",
              " 'locat',\n",
              " 'nhp',\n",
              " 'nobodi',\n",
              " 'find',\n",
              " 'account',\n",
              " 'number',\n",
              " 'walk',\n",
              " 'store',\n",
              " 'explain',\n",
              " 'find',\n",
              " 'acct',\n",
              " 'via',\n",
              " 'devic',\n",
              " 'serial',\n",
              " 'refer',\n",
              " 'wireless',\n",
              " 'residenti',\n",
              " 'servic',\n",
              " 'jay',\n",
              " 'tri',\n",
              " 'pay',\n",
              " 'bill',\n",
              " '60',\n",
              " 'day',\n",
              " 'servic',\n",
              " 'rude',\n",
              " 'cs',\n",
              " 'sever',\n",
              " 'transfer',\n",
              " 'look',\n",
              " 'equip',\n",
              " 'give',\n",
              " 'acct',\n",
              " 'light',\n",
              " 'top',\n",
              " 'red',\n",
              " 'jay',\n",
              " 'know',\n",
              " 'router',\n",
              " 'downstair',\n",
              " 'wifi',\n",
              " 'noth',\n",
              " 'connect',\n",
              " 'ethernet',\n",
              " 'light',\n",
              " 'chang',\n",
              " 'router',\n",
              " 'happen',\n",
              " 'jay',\n",
              " 'randomli',\n",
              " 'boot',\n",
              " 'offlin',\n",
              " 'goe',\n",
              " 'fio',\n",
              " 'servic',\n",
              " 'servic',\n",
              " 'go',\n",
              " 'internet',\n",
              " 'light',\n",
              " 'router',\n",
              " 'chang',\n",
              " 'color',\n",
              " 'bcw',\n",
              " 'yep',\n",
              " 'servic',\n",
              " 'cut',\n",
              " 'acm',\n",
              " 'cut',\n",
              " 'everi',\n",
              " '20',\n",
              " 'minut',\n",
              " 'ridicul',\n",
              " 'make',\n",
              " 'feel',\n",
              " 'way',\n",
              " 'fix',\n",
              " 'thing',\n",
              " 'us',\n",
              " 'kmg',\n",
              " 'worst',\n",
              " 'isp',\n",
              " 'ever',\n",
              " 'area',\n",
              " 'locat',\n",
              " 'servic',\n",
              " 'time',\n",
              " 'hsb',\n",
              " 'gt',\n",
              " 'verizon',\n",
              " 'lt',\n",
              " 'expect',\n",
              " 'fix',\n",
              " 'app',\n",
              " 'refer',\n",
              " 'acm',\n",
              " 'fix',\n",
              " 'app',\n",
              " 'even',\n",
              " 'open',\n",
              " 'still',\n",
              " 'think',\n",
              " 'look',\n",
              " 'great',\n",
              " 'becki',\n",
              " 'becki',\n",
              " 'nice',\n",
              " 'fit',\n",
              " 'veggi',\n",
              " 'burrito',\n",
              " 'costum',\n",
              " 'halloween',\n",
              " 'sorri',\n",
              " 'pleas',\n",
              " 'tell',\n",
              " 'us',\n",
              " 'help',\n",
              " 'becki',\n",
              " 'mess',\n",
              " 'today',\n",
              " 'give',\n",
              " '3',\n",
              " 'burrito',\n",
              " 'although',\n",
              " 'dress',\n",
              " 'hope',\n",
              " 'get',\n",
              " 'point',\n",
              " 'becki',\n",
              " 'hey',\n",
              " 'wan',\n",
              " 'na',\n",
              " 'come',\n",
              " 'mammoth',\n",
              " 'least',\n",
              " 'eat',\n",
              " 'week',\n",
              " 'promis',\n",
              " 'guac',\n",
              " 'happi',\n",
              " 'great',\n",
              " 'experi',\n",
              " 'becki',\n",
              " 'excel',\n",
              " 'servic',\n",
              " 'tonight',\n",
              " 'plenti',\n",
              " 'peopl',\n",
              " 'line',\n",
              " 'went',\n",
              " 'fast',\n",
              " 'everyon',\n",
              " 'kind',\n",
              " 'smart',\n",
              " 'tara',\n",
              " 'one',\n",
              " 'costum',\n",
              " 'boorito',\n",
              " 'incred',\n",
              " 'concern',\n",
              " 'pleas',\n",
              " 'tell',\n",
              " 'us',\n",
              " 'becki',\n",
              " 'diet',\n",
              " 'coke',\n",
              " 'liter',\n",
              " 'bone',\n",
              " 'boorito',\n",
              " 'extra',\n",
              " 'spooki',\n",
              " 'nope',\n",
              " 'still',\n",
              " '3',\n",
              " 'becki',\n",
              " 'get',\n",
              " 'queso',\n",
              " 'quac',\n",
              " 'bowl',\n",
              " 'extra',\n",
              " 'stop',\n",
              " 'costum',\n",
              " '10',\n",
              " '31',\n",
              " '3pm',\n",
              " 'close',\n",
              " 'offici',\n",
              " 'rule',\n",
              " 'mean',\n",
              " 'boorito',\n",
              " 'basic',\n",
              " 'adult',\n",
              " 'version',\n",
              " 'halloween',\n",
              " 'becki',\n",
              " 'happi',\n",
              " 'halloween',\n",
              " 'sinc',\n",
              " 'old',\n",
              " 'trick',\n",
              " 'treat',\n",
              " 'look',\n",
              " 'forward',\n",
              " '3',\n",
              " 'boorito',\n",
              " 'got',\n",
              " 'mine',\n",
              " 'earlier',\n",
              " 'glad',\n",
              " 'could',\n",
              " 'help',\n",
              " 'work',\n",
              " 'like',\n",
              " 'share',\n",
              " 'prais',\n",
              " 'becki',\n",
              " 'thank',\n",
              " 'resolv',\n",
              " 'issu',\n",
              " 'quickli',\n",
              " 'best',\n",
              " 'fanforlif',\n",
              " 'frustrat',\n",
              " 'order',\n",
              " 'dinner',\n",
              " 'saturday',\n",
              " 'use',\n",
              " 'app',\n",
              " 'order',\n",
              " 'wrong',\n",
              " 'charg',\n",
              " 'credit',\n",
              " 'card',\n",
              " 'twice',\n",
              " 'u',\n",
              " 'locat',\n",
              " 'particip',\n",
              " 'becki',\n",
              " 'btw',\n",
              " 'give',\n",
              " '3',\n",
              " 'burrito',\n",
              " 'dress',\n",
              " 'halloween',\n",
              " 'call',\n",
              " 'chipotl',\n",
              " 'make',\n",
              " 'sure',\n",
              " 'select',\n",
              " 'one',\n",
              " 'apolog',\n",
              " 'sent',\n",
              " 'dm',\n",
              " 'help',\n",
              " 'becki',\n",
              " 'tri',\n",
              " 'work',\n",
              " 'rude',\n",
              " 'give',\n",
              " 'tri',\n",
              " 'tara',\n",
              " 'dress',\n",
              " 'still',\n",
              " 'qualifi',\n",
              " 'boorito',\n",
              " 'best',\n",
              " 'kind',\n",
              " 'trick',\n",
              " 'treat',\n",
              " 'treat',\n",
              " 'friend',\n",
              " 'becki',\n",
              " 'everi',\n",
              " 'year',\n",
              " 'trick',\n",
              " 'treat',\n",
              " 'routin',\n",
              " 'walk',\n",
              " 'chipotl',\n",
              " 'spend',\n",
              " '3',\n",
              " 'dollar',\n",
              " 'walk',\n",
              " 'back',\n",
              " 'home',\n",
              " 'incred',\n",
              " 'concern',\n",
              " 'pleas',\n",
              " 'provid',\n",
              " 'detail',\n",
              " 'investig',\n",
              " 'becki',\n",
              " 'nasti',\n",
              " 'use',\n",
              " 'napkin',\n",
              " 'someon',\n",
              " 'food',\n",
              " 'bummer',\n",
              " 'sorri',\n",
              " 'far',\n",
              " 'away',\n",
              " 'closest',\n",
              " 'locat',\n",
              " 'becki',\n",
              " '3',\n",
              " 'burrito',\n",
              " 'nowher',\n",
              " 'near',\n",
              " 'note',\n",
              " 'becki',\n",
              " 'also',\n",
              " 'got',\n",
              " 'onesi',\n",
              " 'target',\n",
              " 'cozi',\n",
              " 'thank',\n",
              " 'becki',\n",
              " 'feel',\n",
              " 'sorri',\n",
              " 'fianc',\n",
              " 'drive',\n",
              " 'c',\n",
              " 'mississippi',\n",
              " 'tonight',\n",
              " 'alon',\n",
              " 'also',\n",
              " 'want',\n",
              " 'llama',\n",
              " 'onesi',\n",
              " 'becki',\n",
              " 'consid',\n",
              " 'walk',\n",
              " 'llama',\n",
              " 'onesi',\n",
              " 'alon',\n",
              " 'happi',\n",
              " 'halloween',\n",
              " 'love',\n",
              " 'thank',\n",
              " 'much',\n",
              " 'stop',\n",
              " 'becki',\n",
              " 'name',\n",
              " 'better',\n",
              " 'halloween',\n",
              " 'duo',\n",
              " 'speedwaybrick',\n",
              " 'uttranscript',\n",
              " 'info',\n",
              " 'share',\n",
              " 'moment',\n",
              " 'feel',\n",
              " 'free',\n",
              " 'keep',\n",
              " 'eye',\n",
              " 'ps',\n",
              " 'blog',\n",
              " 'news',\n",
              " 'updat',\n",
              " 'get',\n",
              " 'help',\n",
              " 'alreadi']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Stem_words = []\n",
        "ps = PorterStemmer()\n",
        "\n",
        "listToStr = ' '.join(map(str, filtered_Sentence))\n",
        "words = word_tokenize(listToStr)\n",
        "\n",
        "for i in words:\n",
        "    rootWord = ps.stem(i)\n",
        "    Stem_words.append(rootWord)\n",
        "    \n",
        "Stem_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyIe2pgwZtjd",
        "outputId": "5e34d457-42ce-4a79-98df-9f610a53c80d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The text after lemmatization\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['understand would like assist would need get private secured link assist',\n",
              " 'propose',\n",
              " 'sent several private messages one responding usual',\n",
              " 'please send us private message assist click message top profile',\n",
              " '',\n",
              " 'please send us private message gain details account',\n",
              " 'worst customer service',\n",
              " 'saddening hear please shoot us dm look kc',\n",
              " 'gon na magically change connectivity whole family',\n",
              " 'understand concerns like please send us direct message assist aa',\n",
              " 'since signed since day 1',\n",
              " 'h definitely like work long experiencing issue aa',\n",
              " 'lie great connection 5 bars lte still load something smh',\n",
              " 'please send private message send link access account fr',\n",
              " 'whenever contact customer support tell shortcode enabled account never 4 years tried',\n",
              " 'information incorrect jk',\n",
              " 'spectrum would like email copy one since spectrum updating training',\n",
              " 'department part corporate office particular area gone format unawa',\n",
              " 'spectrum received corporate office would like copy',\n",
              " 'thank jk',\n",
              " 'spectrum correct way via ocs account takeover email consent form need done local office',\n",
              " 'spectrum incorrect information form front faxed maybe need maintain date information',\n",
              " 'information pertaining account assumption correct need done local outlet wit',\n",
              " 'actually broken link sent incorrect information',\n",
              " 'hello apologies frustrations inconvenience happy look mg',\n",
              " 'yo spectrum customer service reps super nice imma start trippin get service going',\n",
              " 'apologize inconvenience glad assist dm name acct phone jb',\n",
              " 'picture spectrum pretty much every day pay 171 per month',\n",
              " 'help arrived sorry see trouble help hsb',\n",
              " 'finally got someone helped thanks',\n",
              " 'awesome ever need us tweet away hsb',\n",
              " 'somebody please help meeeeee worst luck customer service',\n",
              " 'friend message us acm',\n",
              " 'friend without internet need play videogames together please skills diminish every moment without internetz',\n",
              " 'please follow dm us look order hsb',\n",
              " 'else provide refuse help validate account',\n",
              " 'would able verify anything without authenticating account jay',\n",
              " 'phone number email get equipment service literally trying pay nobody find',\n",
              " 'use order number locate account need secure one one chat please follow dm us hsb',\n",
              " 'md sent wrong address',\n",
              " 'hello duke copy bill state services located nhp',\n",
              " 'nobody find account number walked store explained find acct via devices serial',\n",
              " 'referring wireless residential service jay',\n",
              " 'tried pay bill 60 days service rude cs several transfers look equipment give acct',\n",
              " 'light top red jay',\n",
              " 'know router downstairs wifi nothing connected ethernet',\n",
              " 'lights change router happened jay',\n",
              " 'randomly boots offline goes',\n",
              " 'fios service services go internet light router change color bcw',\n",
              " 'yep',\n",
              " 'services cutting acm',\n",
              " 'cuts every 20 minutes ridiculous',\n",
              " 'make feel way fix things us kmg',\n",
              " 'worst isp ever',\n",
              " 'area located services time hsb',\n",
              " 'gt verizon lt expect fix',\n",
              " 'app referring acm',\n",
              " 'fix app even open',\n",
              " 'still think look great becky',\n",
              " 'becky nice',\n",
              " 'fit veggie burrito costume halloween',\n",
              " 'sorry please tell us help becky',\n",
              " 'messed today give 3 burrito although dressed',\n",
              " 'hopefully get point becky',\n",
              " 'hey wan na come mammoth least eat week promise',\n",
              " 'guac happy great experience becky',\n",
              " 'excellent service tonight plenty people line went fast everyone kind',\n",
              " 'smart tara',\n",
              " 'one costume boorito',\n",
              " 'incredibly concerning please tell us becky',\n",
              " 'diet coke literal bone boorito extra spooky',\n",
              " 'nope still 3 becky',\n",
              " 'get queso quac bowl extra',\n",
              " 'stop costume 10 31 3pm close official rules',\n",
              " 'mean boorito basically adult version halloween becky',\n",
              " 'happy halloween since old trick treat look forward 3 booritos got mine earlier',\n",
              " 'glad could help work like share praise becky',\n",
              " 'thank resolving issue quickly best fanforlife',\n",
              " 'frustrated ordered dinner saturday using app order wrong charged credit card twice',\n",
              " 'u locations participating becky',\n",
              " 'btw giving 3 burritos dress halloween call chipotle make sure select ones',\n",
              " 'apologies sent dm help becky',\n",
              " 'tried work rude',\n",
              " 'give try tara',\n",
              " 'dress still qualify boorito',\n",
              " 'best kind trick treating treats friend becky',\n",
              " 'every year trick treating routine walking chipotle spending 3 dollars walking back home',\n",
              " 'incredibly concerning please provide details investigate becky',\n",
              " 'nasty used napkin someone food',\n",
              " 'bummer sorry far away closest location becky',\n",
              " '3 burritos nowhere near',\n",
              " 'noted becky',\n",
              " 'also got onesie target cozy',\n",
              " 'thanks becky feeling sorry fianc driving c mississippi tonight',\n",
              " 'alone also want llama onesie becky',\n",
              " 'considering walking llama onesie alone happy halloween',\n",
              " 'love thanks much stopping becky',\n",
              " 'name better halloween duo speedwaybrick uttranscript',\n",
              " 'info share moment feel free keep eye ps blog news updates',\n",
              " 'get help already']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#text after applying lemmatization \n",
        "lemma_word = []\n",
        "\n",
        "\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "for w in filtered_Sentence:\n",
        "    word1 = wordnet_lemmatizer.lemmatize(w, pos = \"n\")\n",
        "    word2 = wordnet_lemmatizer.lemmatize(word1, pos = \"v\")\n",
        "    word3 = wordnet_lemmatizer.lemmatize(word2, pos = (\"a\"))\n",
        "    lemma_word.append(word1)\n",
        "print(\"The text after lemmatization\")\n",
        "\n",
        "lemma_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tbjFrCyOZtjf"
      },
      "outputs": [],
      "source": [
        "#inverted index\n",
        "def generate_inverted_index(data: list):\n",
        "    inv_idx_dict = {}\n",
        "     \n",
        "    for index, doc_text in enumerate(data):\n",
        "        for word in doc_text.split():\n",
        "            if word not in inv_idx_dict.keys():\n",
        "                inv_idx_dict[word] = [index]\n",
        "            elif index not in inv_idx_dict[word]:\n",
        "                inv_idx_dict[word].append(index)\n",
        "    return inv_idx_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jOaP5ytZtjh",
        "outputId": "7bafaf3b-0cdb-4162-b826-519469b7ee48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'understand': [0, 9],\n",
              " 'would': [0, 16, 18, 36],\n",
              " 'like': [0, 9, 11, 16, 18, 76],\n",
              " 'assist': [0, 3, 9, 26],\n",
              " 'need': [0, 20, 21, 22, 30, 33, 38],\n",
              " 'get': [0, 25, 37, 63, 72, 99],\n",
              " 'private': [0, 2, 3, 5, 13],\n",
              " 'secured': [0],\n",
              " 'link': [0, 13, 23],\n",
              " 'propose': [1],\n",
              " 'sent': [2, 23, 39, 81],\n",
              " 'several': [2, 43],\n",
              " 'messages': [2],\n",
              " 'one': [2, 16, 38, 68],\n",
              " 'responding': [2],\n",
              " 'usual': [2],\n",
              " 'please': [3, 5, 7, 9, 13, 31, 33, 34, 38, 61, 69, 87],\n",
              " 'send': [3, 5, 9, 13],\n",
              " 'us': [3, 5, 7, 9, 30, 32, 34, 38, 52, 61, 69],\n",
              " 'message': [3, 5, 9, 13, 32],\n",
              " 'click': [3],\n",
              " 'top': [3, 44],\n",
              " 'profile': [3],\n",
              " 'gain': [5],\n",
              " 'details': [5, 87],\n",
              " 'account': [5, 13, 14, 20, 22, 35, 36, 38, 41],\n",
              " 'worst': [6, 31, 53],\n",
              " 'customer': [6, 14, 25, 31],\n",
              " 'service': [6, 25, 31, 37, 42, 43, 48, 66],\n",
              " 'saddening': [7],\n",
              " 'hear': [7],\n",
              " 'shoot': [7],\n",
              " 'dm': [7, 26, 34, 38, 81],\n",
              " 'look': [7, 24, 34, 43, 58, 75],\n",
              " 'kc': [7],\n",
              " 'gon': [8],\n",
              " 'na': [8, 64],\n",
              " 'magically': [8],\n",
              " 'change': [8, 46, 48],\n",
              " 'connectivity': [8],\n",
              " 'whole': [8],\n",
              " 'family': [8],\n",
              " 'concerns': [9],\n",
              " 'direct': [9],\n",
              " 'aa': [9, 11],\n",
              " 'since': [10, 16, 75],\n",
              " 'signed': [10],\n",
              " 'day': [10, 27],\n",
              " '1': [10],\n",
              " 'h': [11],\n",
              " 'definitely': [11],\n",
              " 'work': [11, 76, 82],\n",
              " 'long': [11],\n",
              " 'experiencing': [11],\n",
              " 'issue': [11, 77],\n",
              " 'lie': [12],\n",
              " 'great': [12, 58, 65],\n",
              " 'connection': [12],\n",
              " '5': [12],\n",
              " 'bars': [12],\n",
              " 'lte': [12],\n",
              " 'still': [12, 58, 71, 84],\n",
              " 'load': [12],\n",
              " 'something': [12],\n",
              " 'smh': [12],\n",
              " 'access': [13],\n",
              " 'fr': [13],\n",
              " 'whenever': [14],\n",
              " 'contact': [14],\n",
              " 'support': [14],\n",
              " 'tell': [14, 61, 69],\n",
              " 'shortcode': [14],\n",
              " 'enabled': [14],\n",
              " 'never': [14],\n",
              " '4': [14],\n",
              " 'years': [14],\n",
              " 'tried': [14, 43, 82],\n",
              " 'information': [15, 21, 22, 23],\n",
              " 'incorrect': [15, 21, 23],\n",
              " 'jk': [15, 19],\n",
              " 'spectrum': [16, 18, 20, 21, 25, 27],\n",
              " 'email': [16, 20, 37],\n",
              " 'copy': [16, 18, 40],\n",
              " 'updating': [16],\n",
              " 'training': [16],\n",
              " 'department': [17],\n",
              " 'part': [17],\n",
              " 'corporate': [17, 18],\n",
              " 'office': [17, 18, 20],\n",
              " 'particular': [17],\n",
              " 'area': [17, 54],\n",
              " 'gone': [17],\n",
              " 'format': [17],\n",
              " 'unawa': [17],\n",
              " 'received': [18],\n",
              " 'thank': [19, 77],\n",
              " 'correct': [20, 22],\n",
              " 'way': [20, 52],\n",
              " 'via': [20, 41],\n",
              " 'ocs': [20],\n",
              " 'takeover': [20],\n",
              " 'consent': [20],\n",
              " 'form': [20, 21],\n",
              " 'done': [20, 22],\n",
              " 'local': [20, 22],\n",
              " 'front': [21],\n",
              " 'faxed': [21],\n",
              " 'maybe': [21],\n",
              " 'maintain': [21],\n",
              " 'date': [21],\n",
              " 'pertaining': [22],\n",
              " 'assumption': [22],\n",
              " 'outlet': [22],\n",
              " 'wit': [22],\n",
              " 'actually': [23],\n",
              " 'broken': [23],\n",
              " 'hello': [24, 40],\n",
              " 'apologies': [24, 81],\n",
              " 'frustrations': [24],\n",
              " 'inconvenience': [24, 26],\n",
              " 'happy': [24, 65, 75, 95],\n",
              " 'mg': [24],\n",
              " 'yo': [25],\n",
              " 'reps': [25],\n",
              " 'super': [25],\n",
              " 'nice': [25, 59],\n",
              " 'imma': [25],\n",
              " 'start': [25],\n",
              " 'trippin': [25],\n",
              " 'going': [25],\n",
              " 'apologize': [26],\n",
              " 'glad': [26, 76],\n",
              " 'name': [26, 97],\n",
              " 'acct': [26, 41, 43],\n",
              " 'phone': [26, 37],\n",
              " 'jb': [26],\n",
              " 'picture': [27],\n",
              " 'pretty': [27],\n",
              " 'much': [27, 96],\n",
              " 'every': [27, 33, 51, 86],\n",
              " 'pay': [27, 37, 43],\n",
              " '171': [27],\n",
              " 'per': [27],\n",
              " 'month': [27],\n",
              " 'help': [28, 31, 35, 61, 76, 81, 99],\n",
              " 'arrived': [28],\n",
              " 'sorry': [28, 61, 89, 93],\n",
              " 'see': [28],\n",
              " 'trouble': [28],\n",
              " 'hsb': [28, 30, 34, 38, 54],\n",
              " 'finally': [29],\n",
              " 'got': [29, 75, 92],\n",
              " 'someone': [29, 88],\n",
              " 'helped': [29],\n",
              " 'thanks': [29, 93, 96],\n",
              " 'awesome': [30],\n",
              " 'ever': [30, 53],\n",
              " 'tweet': [30],\n",
              " 'away': [30, 89],\n",
              " 'somebody': [31],\n",
              " 'meeeeee': [31],\n",
              " 'luck': [31],\n",
              " 'friend': [32, 33, 85],\n",
              " 'acm': [32, 50, 56],\n",
              " 'without': [33, 36],\n",
              " 'internet': [33, 48],\n",
              " 'play': [33],\n",
              " 'videogames': [33],\n",
              " 'together': [33],\n",
              " 'skills': [33],\n",
              " 'diminish': [33],\n",
              " 'moment': [33, 98],\n",
              " 'internetz': [33],\n",
              " 'follow': [34, 38],\n",
              " 'order': [34, 38, 78],\n",
              " 'else': [35],\n",
              " 'provide': [35, 87],\n",
              " 'refuse': [35],\n",
              " 'validate': [35],\n",
              " 'able': [36],\n",
              " 'verify': [36],\n",
              " 'anything': [36],\n",
              " 'authenticating': [36],\n",
              " 'jay': [36, 42, 44, 46],\n",
              " 'number': [37, 38, 41],\n",
              " 'equipment': [37, 43],\n",
              " 'literally': [37],\n",
              " 'trying': [37],\n",
              " 'nobody': [37, 41],\n",
              " 'find': [37, 41],\n",
              " 'use': [38],\n",
              " 'locate': [38],\n",
              " 'secure': [38],\n",
              " 'chat': [38],\n",
              " 'md': [39],\n",
              " 'wrong': [39, 78],\n",
              " 'address': [39],\n",
              " 'duke': [40],\n",
              " 'bill': [40, 43],\n",
              " 'state': [40],\n",
              " 'services': [40, 48, 50, 54],\n",
              " 'located': [40, 54],\n",
              " 'nhp': [40],\n",
              " 'walked': [41],\n",
              " 'store': [41],\n",
              " 'explained': [41],\n",
              " 'devices': [41],\n",
              " 'serial': [41],\n",
              " 'referring': [42, 56],\n",
              " 'wireless': [42],\n",
              " 'residential': [42],\n",
              " '60': [43],\n",
              " 'days': [43],\n",
              " 'rude': [43, 82],\n",
              " 'cs': [43],\n",
              " 'transfers': [43],\n",
              " 'give': [43, 62, 83],\n",
              " 'light': [44, 48],\n",
              " 'red': [44],\n",
              " 'know': [45],\n",
              " 'router': [45, 46, 48],\n",
              " 'downstairs': [45],\n",
              " 'wifi': [45],\n",
              " 'nothing': [45],\n",
              " 'connected': [45],\n",
              " 'ethernet': [45],\n",
              " 'lights': [46],\n",
              " 'happened': [46],\n",
              " 'randomly': [47],\n",
              " 'boots': [47],\n",
              " 'offline': [47],\n",
              " 'goes': [47],\n",
              " 'fios': [48],\n",
              " 'go': [48],\n",
              " 'color': [48],\n",
              " 'bcw': [48],\n",
              " 'yep': [49],\n",
              " 'cutting': [50],\n",
              " 'cuts': [51],\n",
              " '20': [51],\n",
              " 'minutes': [51],\n",
              " 'ridiculous': [51],\n",
              " 'make': [52, 80],\n",
              " 'feel': [52, 98],\n",
              " 'fix': [52, 55, 57],\n",
              " 'things': [52],\n",
              " 'kmg': [52],\n",
              " 'isp': [53],\n",
              " 'time': [54],\n",
              " 'gt': [55],\n",
              " 'verizon': [55],\n",
              " 'lt': [55],\n",
              " 'expect': [55],\n",
              " 'app': [56, 57, 78],\n",
              " 'even': [57],\n",
              " 'open': [57],\n",
              " 'think': [58],\n",
              " 'becky': [58,\n",
              "  59,\n",
              "  61,\n",
              "  63,\n",
              "  65,\n",
              "  69,\n",
              "  71,\n",
              "  74,\n",
              "  76,\n",
              "  79,\n",
              "  81,\n",
              "  85,\n",
              "  87,\n",
              "  89,\n",
              "  91,\n",
              "  93,\n",
              "  94,\n",
              "  96],\n",
              " 'fit': [60],\n",
              " 'veggie': [60],\n",
              " 'burrito': [60, 62],\n",
              " 'costume': [60, 68, 73],\n",
              " 'halloween': [60, 74, 75, 80, 95, 97],\n",
              " 'messed': [62],\n",
              " 'today': [62],\n",
              " '3': [62, 71, 75, 80, 86, 90],\n",
              " 'although': [62],\n",
              " 'dressed': [62],\n",
              " 'hopefully': [63],\n",
              " 'point': [63],\n",
              " 'hey': [64],\n",
              " 'wan': [64],\n",
              " 'come': [64],\n",
              " 'mammoth': [64],\n",
              " 'least': [64],\n",
              " 'eat': [64],\n",
              " 'week': [64],\n",
              " 'promise': [64],\n",
              " 'guac': [65],\n",
              " 'experience': [65],\n",
              " 'excellent': [66],\n",
              " 'tonight': [66, 93],\n",
              " 'plenty': [66],\n",
              " 'people': [66],\n",
              " 'line': [66],\n",
              " 'went': [66],\n",
              " 'fast': [66],\n",
              " 'everyone': [66],\n",
              " 'kind': [66, 85],\n",
              " 'smart': [67],\n",
              " 'tara': [67, 83],\n",
              " 'boorito': [68, 70, 74, 84],\n",
              " 'incredibly': [69, 87],\n",
              " 'concerning': [69, 87],\n",
              " 'diet': [70],\n",
              " 'coke': [70],\n",
              " 'literal': [70],\n",
              " 'bone': [70],\n",
              " 'extra': [70, 72],\n",
              " 'spooky': [70],\n",
              " 'nope': [71],\n",
              " 'queso': [72],\n",
              " 'quac': [72],\n",
              " 'bowl': [72],\n",
              " 'stop': [73],\n",
              " '10': [73],\n",
              " '31': [73],\n",
              " '3pm': [73],\n",
              " 'close': [73],\n",
              " 'official': [73],\n",
              " 'rules': [73],\n",
              " 'mean': [74],\n",
              " 'basically': [74],\n",
              " 'adult': [74],\n",
              " 'version': [74],\n",
              " 'old': [75],\n",
              " 'trick': [75, 85, 86],\n",
              " 'treat': [75],\n",
              " 'forward': [75],\n",
              " 'booritos': [75],\n",
              " 'mine': [75],\n",
              " 'earlier': [75],\n",
              " 'could': [76],\n",
              " 'share': [76, 98],\n",
              " 'praise': [76],\n",
              " 'resolving': [77],\n",
              " 'quickly': [77],\n",
              " 'best': [77, 85],\n",
              " 'fanforlife': [77],\n",
              " 'frustrated': [78],\n",
              " 'ordered': [78],\n",
              " 'dinner': [78],\n",
              " 'saturday': [78],\n",
              " 'using': [78],\n",
              " 'charged': [78],\n",
              " 'credit': [78],\n",
              " 'card': [78],\n",
              " 'twice': [78],\n",
              " 'u': [79],\n",
              " 'locations': [79],\n",
              " 'participating': [79],\n",
              " 'btw': [80],\n",
              " 'giving': [80],\n",
              " 'burritos': [80, 90],\n",
              " 'dress': [80, 84],\n",
              " 'call': [80],\n",
              " 'chipotle': [80, 86],\n",
              " 'sure': [80],\n",
              " 'select': [80],\n",
              " 'ones': [80],\n",
              " 'try': [83],\n",
              " 'qualify': [84],\n",
              " 'treating': [85, 86],\n",
              " 'treats': [85],\n",
              " 'year': [86],\n",
              " 'routine': [86],\n",
              " 'walking': [86, 95],\n",
              " 'spending': [86],\n",
              " 'dollars': [86],\n",
              " 'back': [86],\n",
              " 'home': [86],\n",
              " 'investigate': [87],\n",
              " 'nasty': [88],\n",
              " 'used': [88],\n",
              " 'napkin': [88],\n",
              " 'food': [88],\n",
              " 'bummer': [89],\n",
              " 'far': [89],\n",
              " 'closest': [89],\n",
              " 'location': [89],\n",
              " 'nowhere': [90],\n",
              " 'near': [90],\n",
              " 'noted': [91],\n",
              " 'also': [92, 94],\n",
              " 'onesie': [92, 94, 95],\n",
              " 'target': [92],\n",
              " 'cozy': [92],\n",
              " 'feeling': [93],\n",
              " 'fianc': [93],\n",
              " 'driving': [93],\n",
              " 'c': [93],\n",
              " 'mississippi': [93],\n",
              " 'alone': [94, 95],\n",
              " 'want': [94],\n",
              " 'llama': [94, 95],\n",
              " 'considering': [95],\n",
              " 'love': [96],\n",
              " 'stopping': [96],\n",
              " 'better': [97],\n",
              " 'duo': [97],\n",
              " 'speedwaybrick': [97],\n",
              " 'uttranscript': [97],\n",
              " 'info': [98],\n",
              " 'free': [98],\n",
              " 'keep': [98],\n",
              " 'eye': [98],\n",
              " 'ps': [98],\n",
              " 'blog': [98],\n",
              " 'news': [98],\n",
              " 'updates': [98],\n",
              " 'already': [99]}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inverted_index = generate_inverted_index(filtered_Sentence)\n",
        "inverted_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "x1TrXMO_Ztjn"
      },
      "outputs": [],
      "source": [
        "#positional index\n",
        "vocab = []\n",
        "postings = {}\n",
        "def generate_positional_index(data: list):\n",
        "  for index,doc_text in enumerate(data):\n",
        "      for word in doc_text.split():\n",
        "          if word not in vocab:\n",
        "              vocab.append(word)\n",
        "          wordId = vocab.index(word)\n",
        "          if word not in postings:\n",
        "              postings[word] = [index]\n",
        "          else:\n",
        "              postings[word].append(index)\n",
        "          #print(wordId,word)\n",
        "  for i in postings:\n",
        "      postings[i]=[len(set(postings[i])),list(set(postings[i]))]\n",
        "  dictionary_items = postings.items()\n",
        "  for i in dictionary_items:\n",
        "    print(i)\n",
        "  #print(postings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbSBT2POZtjp",
        "outputId": "e06a233b-4c6b-4fb6-c9d1-d600a88a0f83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('understand', [2, [0, 9]])\n",
            "('would', [4, [0, 16, 18, 36]])\n",
            "('like', [6, [0, 9, 11, 76, 16, 18]])\n",
            "('assist', [4, [0, 9, 26, 3]])\n",
            "('need', [7, [0, 33, 38, 20, 21, 22, 30]])\n",
            "('get', [6, [0, 99, 37, 72, 25, 63]])\n",
            "('private', [5, [0, 2, 3, 5, 13]])\n",
            "('secured', [1, [0]])\n",
            "('link', [3, [0, 13, 23]])\n",
            "('propose', [1, [1]])\n",
            "('sent', [4, [81, 2, 39, 23]])\n",
            "('several', [2, [2, 43]])\n",
            "('messages', [1, [2]])\n",
            "('one', [4, [16, 2, 68, 38]])\n",
            "('responding', [1, [2]])\n",
            "('usual', [1, [2]])\n",
            "('please', [12, [33, 34, 3, 5, 38, 7, 69, 9, 13, 87, 61, 31]])\n",
            "('send', [4, [9, 13, 3, 5]])\n",
            "('us', [11, [32, 34, 3, 5, 38, 7, 69, 9, 52, 61, 30]])\n",
            "('message', [5, [32, 3, 5, 9, 13]])\n",
            "('click', [1, [3]])\n",
            "('top', [2, [3, 44]])\n",
            "('profile', [1, [3]])\n",
            "('gain', [1, [5]])\n",
            "('details', [2, [5, 87]])\n",
            "('account', [9, [35, 36, 5, 38, 41, 13, 14, 20, 22]])\n",
            "('worst', [3, [53, 6, 31]])\n",
            "('customer', [4, [25, 31, 6, 14]])\n",
            "('service', [8, [66, 37, 6, 42, 43, 48, 25, 31]])\n",
            "('saddening', [1, [7]])\n",
            "('hear', [1, [7]])\n",
            "('shoot', [1, [7]])\n",
            "('dm', [5, [34, 38, 7, 81, 26]])\n",
            "('look', [6, [34, 7, 43, 75, 24, 58]])\n",
            "('kc', [1, [7]])\n",
            "('gon', [1, [8]])\n",
            "('na', [2, [8, 64]])\n",
            "('magically', [1, [8]])\n",
            "('change', [3, [8, 48, 46]])\n",
            "('connectivity', [1, [8]])\n",
            "('whole', [1, [8]])\n",
            "('family', [1, [8]])\n",
            "('concerns', [1, [9]])\n",
            "('direct', [1, [9]])\n",
            "('aa', [2, [9, 11]])\n",
            "('since', [3, [16, 10, 75]])\n",
            "('signed', [1, [10]])\n",
            "('day', [2, [10, 27]])\n",
            "('1', [1, [10]])\n",
            "('h', [1, [11]])\n",
            "('definitely', [1, [11]])\n",
            "('work', [3, [82, 11, 76]])\n",
            "('long', [1, [11]])\n",
            "('experiencing', [1, [11]])\n",
            "('issue', [2, [11, 77]])\n",
            "('lie', [1, [12]])\n",
            "('great', [3, [65, 58, 12]])\n",
            "('connection', [1, [12]])\n",
            "('5', [1, [12]])\n",
            "('bars', [1, [12]])\n",
            "('lte', [1, [12]])\n",
            "('still', [4, [58, 12, 84, 71]])\n",
            "('load', [1, [12]])\n",
            "('something', [1, [12]])\n",
            "('smh', [1, [12]])\n",
            "('access', [1, [13]])\n",
            "('fr', [1, [13]])\n",
            "('whenever', [1, [14]])\n",
            "('contact', [1, [14]])\n",
            "('support', [1, [14]])\n",
            "('tell', [3, [69, 61, 14]])\n",
            "('shortcode', [1, [14]])\n",
            "('enabled', [1, [14]])\n",
            "('never', [1, [14]])\n",
            "('4', [1, [14]])\n",
            "('years', [1, [14]])\n",
            "('tried', [3, [82, 43, 14]])\n",
            "('information', [4, [23, 21, 22, 15]])\n",
            "('incorrect', [3, [23, 21, 15]])\n",
            "('jk', [2, [19, 15]])\n",
            "('spectrum', [6, [16, 18, 20, 21, 25, 27]])\n",
            "('email', [3, [16, 20, 37]])\n",
            "('copy', [3, [16, 18, 40]])\n",
            "('updating', [1, [16]])\n",
            "('training', [1, [16]])\n",
            "('department', [1, [17]])\n",
            "('part', [1, [17]])\n",
            "('corporate', [2, [17, 18]])\n",
            "('office', [3, [17, 18, 20]])\n",
            "('particular', [1, [17]])\n",
            "('area', [2, [17, 54]])\n",
            "('gone', [1, [17]])\n",
            "('format', [1, [17]])\n",
            "('unawa', [1, [17]])\n",
            "('received', [1, [18]])\n",
            "('thank', [2, [19, 77]])\n",
            "('correct', [2, [20, 22]])\n",
            "('way', [2, [20, 52]])\n",
            "('via', [2, [41, 20]])\n",
            "('ocs', [1, [20]])\n",
            "('takeover', [1, [20]])\n",
            "('consent', [1, [20]])\n",
            "('form', [2, [20, 21]])\n",
            "('done', [2, [20, 22]])\n",
            "('local', [2, [20, 22]])\n",
            "('front', [1, [21]])\n",
            "('faxed', [1, [21]])\n",
            "('maybe', [1, [21]])\n",
            "('maintain', [1, [21]])\n",
            "('date', [1, [21]])\n",
            "('pertaining', [1, [22]])\n",
            "('assumption', [1, [22]])\n",
            "('outlet', [1, [22]])\n",
            "('wit', [1, [22]])\n",
            "('actually', [1, [23]])\n",
            "('broken', [1, [23]])\n",
            "('hello', [2, [24, 40]])\n",
            "('apologies', [2, [24, 81]])\n",
            "('frustrations', [1, [24]])\n",
            "('inconvenience', [2, [24, 26]])\n",
            "('happy', [4, [24, 65, 75, 95]])\n",
            "('mg', [1, [24]])\n",
            "('yo', [1, [25]])\n",
            "('reps', [1, [25]])\n",
            "('super', [1, [25]])\n",
            "('nice', [2, [25, 59]])\n",
            "('imma', [1, [25]])\n",
            "('start', [1, [25]])\n",
            "('trippin', [1, [25]])\n",
            "('going', [1, [25]])\n",
            "('apologize', [1, [26]])\n",
            "('glad', [2, [26, 76]])\n",
            "('name', [2, [97, 26]])\n",
            "('acct', [3, [41, 26, 43]])\n",
            "('phone', [2, [26, 37]])\n",
            "('jb', [1, [26]])\n",
            "('picture', [1, [27]])\n",
            "('pretty', [1, [27]])\n",
            "('much', [2, [96, 27]])\n",
            "('every', [4, [33, 27, 51, 86]])\n",
            "('pay', [3, [43, 27, 37]])\n",
            "('171', [1, [27]])\n",
            "('per', [1, [27]])\n",
            "('month', [1, [27]])\n",
            "('help', [7, [35, 99, 76, 81, 28, 61, 31]])\n",
            "('arrived', [1, [28]])\n",
            "('sorry', [4, [89, 93, 28, 61]])\n",
            "('see', [1, [28]])\n",
            "('trouble', [1, [28]])\n",
            "('hsb', [5, [34, 38, 54, 28, 30]])\n",
            "('finally', [1, [29]])\n",
            "('got', [3, [75, 92, 29]])\n",
            "('someone', [2, [88, 29]])\n",
            "('helped', [1, [29]])\n",
            "('thanks', [3, [96, 93, 29]])\n",
            "('awesome', [1, [30]])\n",
            "('ever', [2, [53, 30]])\n",
            "('tweet', [1, [30]])\n",
            "('away', [2, [89, 30]])\n",
            "('somebody', [1, [31]])\n",
            "('meeeeee', [1, [31]])\n",
            "('luck', [1, [31]])\n",
            "('friend', [3, [32, 33, 85]])\n",
            "('acm', [3, [32, 50, 56]])\n",
            "('without', [2, [33, 36]])\n",
            "('internet', [2, [48, 33]])\n",
            "('play', [1, [33]])\n",
            "('videogames', [1, [33]])\n",
            "('together', [1, [33]])\n",
            "('skills', [1, [33]])\n",
            "('diminish', [1, [33]])\n",
            "('moment', [2, [33, 98]])\n",
            "('internetz', [1, [33]])\n",
            "('follow', [2, [34, 38]])\n",
            "('order', [3, [78, 34, 38]])\n",
            "('else', [1, [35]])\n",
            "('provide', [2, [35, 87]])\n",
            "('refuse', [1, [35]])\n",
            "('validate', [1, [35]])\n",
            "('able', [1, [36]])\n",
            "('verify', [1, [36]])\n",
            "('anything', [1, [36]])\n",
            "('authenticating', [1, [36]])\n",
            "('jay', [4, [46, 42, 36, 44]])\n",
            "('number', [3, [41, 37, 38]])\n",
            "('equipment', [2, [43, 37]])\n",
            "('literally', [1, [37]])\n",
            "('trying', [1, [37]])\n",
            "('nobody', [2, [41, 37]])\n",
            "('find', [2, [41, 37]])\n",
            "('use', [1, [38]])\n",
            "('locate', [1, [38]])\n",
            "('secure', [1, [38]])\n",
            "('chat', [1, [38]])\n",
            "('md', [1, [39]])\n",
            "('wrong', [2, [78, 39]])\n",
            "('address', [1, [39]])\n",
            "('duke', [1, [40]])\n",
            "('bill', [2, [40, 43]])\n",
            "('state', [1, [40]])\n",
            "('services', [4, [40, 48, 50, 54]])\n",
            "('located', [2, [40, 54]])\n",
            "('nhp', [1, [40]])\n",
            "('walked', [1, [41]])\n",
            "('store', [1, [41]])\n",
            "('explained', [1, [41]])\n",
            "('devices', [1, [41]])\n",
            "('serial', [1, [41]])\n",
            "('referring', [2, [56, 42]])\n",
            "('wireless', [1, [42]])\n",
            "('residential', [1, [42]])\n",
            "('60', [1, [43]])\n",
            "('days', [1, [43]])\n",
            "('rude', [2, [82, 43]])\n",
            "('cs', [1, [43]])\n",
            "('transfers', [1, [43]])\n",
            "('give', [3, [83, 43, 62]])\n",
            "('light', [2, [48, 44]])\n",
            "('red', [1, [44]])\n",
            "('know', [1, [45]])\n",
            "('router', [3, [48, 45, 46]])\n",
            "('downstairs', [1, [45]])\n",
            "('wifi', [1, [45]])\n",
            "('nothing', [1, [45]])\n",
            "('connected', [1, [45]])\n",
            "('ethernet', [1, [45]])\n",
            "('lights', [1, [46]])\n",
            "('happened', [1, [46]])\n",
            "('randomly', [1, [47]])\n",
            "('boots', [1, [47]])\n",
            "('offline', [1, [47]])\n",
            "('goes', [1, [47]])\n",
            "('fios', [1, [48]])\n",
            "('go', [1, [48]])\n",
            "('color', [1, [48]])\n",
            "('bcw', [1, [48]])\n",
            "('yep', [1, [49]])\n",
            "('cutting', [1, [50]])\n",
            "('cuts', [1, [51]])\n",
            "('20', [1, [51]])\n",
            "('minutes', [1, [51]])\n",
            "('ridiculous', [1, [51]])\n",
            "('make', [2, [80, 52]])\n",
            "('feel', [2, [98, 52]])\n",
            "('fix', [3, [57, 52, 55]])\n",
            "('things', [1, [52]])\n",
            "('kmg', [1, [52]])\n",
            "('isp', [1, [53]])\n",
            "('time', [1, [54]])\n",
            "('gt', [1, [55]])\n",
            "('verizon', [1, [55]])\n",
            "('lt', [1, [55]])\n",
            "('expect', [1, [55]])\n",
            "('app', [3, [56, 57, 78]])\n",
            "('even', [1, [57]])\n",
            "('open', [1, [57]])\n",
            "('think', [1, [58]])\n",
            "('becky', [18, [96, 65, 69, 71, 74, 91, 76, 79, 81, 93, 85, 87, 89, 58, 59, 61, 94, 63]])\n",
            "('fit', [1, [60]])\n",
            "('veggie', [1, [60]])\n",
            "('burrito', [2, [60, 62]])\n",
            "('costume', [3, [73, 60, 68]])\n",
            "('halloween', [6, [97, 74, 75, 80, 60, 95]])\n",
            "('messed', [1, [62]])\n",
            "('today', [1, [62]])\n",
            "('3', [6, [71, 75, 80, 86, 90, 62]])\n",
            "('although', [1, [62]])\n",
            "('dressed', [1, [62]])\n",
            "('hopefully', [1, [63]])\n",
            "('point', [1, [63]])\n",
            "('hey', [1, [64]])\n",
            "('wan', [1, [64]])\n",
            "('come', [1, [64]])\n",
            "('mammoth', [1, [64]])\n",
            "('least', [1, [64]])\n",
            "('eat', [1, [64]])\n",
            "('week', [1, [64]])\n",
            "('promise', [1, [64]])\n",
            "('guac', [1, [65]])\n",
            "('experience', [1, [65]])\n",
            "('excellent', [1, [66]])\n",
            "('tonight', [2, [66, 93]])\n",
            "('plenty', [1, [66]])\n",
            "('people', [1, [66]])\n",
            "('line', [1, [66]])\n",
            "('went', [1, [66]])\n",
            "('fast', [1, [66]])\n",
            "('everyone', [1, [66]])\n",
            "('kind', [2, [66, 85]])\n",
            "('smart', [1, [67]])\n",
            "('tara', [2, [83, 67]])\n",
            "('boorito', [4, [74, 68, 70, 84]])\n",
            "('incredibly', [2, [69, 87]])\n",
            "('concerning', [2, [69, 87]])\n",
            "('diet', [1, [70]])\n",
            "('coke', [1, [70]])\n",
            "('literal', [1, [70]])\n",
            "('bone', [1, [70]])\n",
            "('extra', [2, [72, 70]])\n",
            "('spooky', [1, [70]])\n",
            "('nope', [1, [71]])\n",
            "('queso', [1, [72]])\n",
            "('quac', [1, [72]])\n",
            "('bowl', [1, [72]])\n",
            "('stop', [1, [73]])\n",
            "('10', [1, [73]])\n",
            "('31', [1, [73]])\n",
            "('3pm', [1, [73]])\n",
            "('close', [1, [73]])\n",
            "('official', [1, [73]])\n",
            "('rules', [1, [73]])\n",
            "('mean', [1, [74]])\n",
            "('basically', [1, [74]])\n",
            "('adult', [1, [74]])\n",
            "('version', [1, [74]])\n",
            "('old', [1, [75]])\n",
            "('trick', [3, [75, 85, 86]])\n",
            "('treat', [1, [75]])\n",
            "('forward', [1, [75]])\n",
            "('booritos', [1, [75]])\n",
            "('mine', [1, [75]])\n",
            "('earlier', [1, [75]])\n",
            "('could', [1, [76]])\n",
            "('share', [2, [98, 76]])\n",
            "('praise', [1, [76]])\n",
            "('resolving', [1, [77]])\n",
            "('quickly', [1, [77]])\n",
            "('best', [2, [85, 77]])\n",
            "('fanforlife', [1, [77]])\n",
            "('frustrated', [1, [78]])\n",
            "('ordered', [1, [78]])\n",
            "('dinner', [1, [78]])\n",
            "('saturday', [1, [78]])\n",
            "('using', [1, [78]])\n",
            "('charged', [1, [78]])\n",
            "('credit', [1, [78]])\n",
            "('card', [1, [78]])\n",
            "('twice', [1, [78]])\n",
            "('u', [1, [79]])\n",
            "('locations', [1, [79]])\n",
            "('participating', [1, [79]])\n",
            "('btw', [1, [80]])\n",
            "('giving', [1, [80]])\n",
            "('burritos', [2, [80, 90]])\n",
            "('dress', [2, [80, 84]])\n",
            "('call', [1, [80]])\n",
            "('chipotle', [2, [80, 86]])\n",
            "('sure', [1, [80]])\n",
            "('select', [1, [80]])\n",
            "('ones', [1, [80]])\n",
            "('try', [1, [83]])\n",
            "('qualify', [1, [84]])\n",
            "('treating', [2, [85, 86]])\n",
            "('treats', [1, [85]])\n",
            "('year', [1, [86]])\n",
            "('routine', [1, [86]])\n",
            "('walking', [2, [86, 95]])\n",
            "('spending', [1, [86]])\n",
            "('dollars', [1, [86]])\n",
            "('back', [1, [86]])\n",
            "('home', [1, [86]])\n",
            "('investigate', [1, [87]])\n",
            "('nasty', [1, [88]])\n",
            "('used', [1, [88]])\n",
            "('napkin', [1, [88]])\n",
            "('food', [1, [88]])\n",
            "('bummer', [1, [89]])\n",
            "('far', [1, [89]])\n",
            "('closest', [1, [89]])\n",
            "('location', [1, [89]])\n",
            "('nowhere', [1, [90]])\n",
            "('near', [1, [90]])\n",
            "('noted', [1, [91]])\n",
            "('also', [2, [92, 94]])\n",
            "('onesie', [3, [92, 94, 95]])\n",
            "('target', [1, [92]])\n",
            "('cozy', [1, [92]])\n",
            "('feeling', [1, [93]])\n",
            "('fianc', [1, [93]])\n",
            "('driving', [1, [93]])\n",
            "('c', [1, [93]])\n",
            "('mississippi', [1, [93]])\n",
            "('alone', [2, [94, 95]])\n",
            "('want', [1, [94]])\n",
            "('llama', [2, [94, 95]])\n",
            "('considering', [1, [95]])\n",
            "('love', [1, [96]])\n",
            "('stopping', [1, [96]])\n",
            "('better', [1, [97]])\n",
            "('duo', [1, [97]])\n",
            "('speedwaybrick', [1, [97]])\n",
            "('uttranscript', [1, [97]])\n",
            "('info', [1, [98]])\n",
            "('free', [1, [98]])\n",
            "('keep', [1, [98]])\n",
            "('eye', [1, [98]])\n",
            "('ps', [1, [98]])\n",
            "('blog', [1, [98]])\n",
            "('news', [1, [98]])\n",
            "('updates', [1, [98]])\n",
            "('already', [1, [99]])\n"
          ]
        }
      ],
      "source": [
        "#term->[frequency,[position]]\n",
        "pos_index = generate_positional_index(filtered_Sentence)\n",
        "pos_index"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Single word query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "z0zpIrrYZtjr"
      },
      "outputs": [],
      "source": [
        "#single word query\n",
        "import time\n",
        "def get_word_postings(word):\n",
        "    flag = False\n",
        "    start=time.time()\n",
        "    dictionary_items = postings.items()\n",
        "    for i in dictionary_items:\n",
        "        if(i[0] == word):\n",
        "            flag = True\n",
        "            print(i)\n",
        "            break\n",
        "        else:\n",
        "            time.sleep(0.0000000001)\n",
        "            continue\n",
        "    end=time.time()\n",
        "    time_taken=end-start\n",
        "    if flag:\n",
        "        print(\"Time taken to fetch (single word query): \",time_taken,\"seconds\")\n",
        "    else:\n",
        "        print(\"Could not find the word\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phrase Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EoDiIW0bZtjs"
      },
      "outputs": [],
      "source": [
        "#For finding if two words occur together and in which document.\n",
        "def get_phrase_query(phrase): \n",
        "    \n",
        "    start=time.time()\n",
        "    str_to_process = phrase.split()\n",
        "\n",
        "    i=0\n",
        "    j=0\n",
        "\n",
        "    lim1=0\n",
        "    lim2=0\n",
        "\n",
        "    ans=[]\n",
        "    if (str_to_process[0] in postings) and (str_to_process[1] in postings):\n",
        "        while (lim1<len(postings[str_to_process[0]][1]) and lim2<len(postings[str_to_process[1]][1]) ):\n",
        "            if(postings[str_to_process[0]][1][i] == postings[str_to_process[1]][1][j]):\n",
        "                ans.append(postings[str_to_process[1]][1][j])\n",
        "                i+=1\n",
        "                j+=1\n",
        "\n",
        "            elif (postings[str_to_process[0]][1][i] < postings[str_to_process[1]][1][j]):\n",
        "                i+=1\n",
        "\n",
        "            else:\n",
        "                j+=1\n",
        "\n",
        "            lim1+=1\n",
        "            lim2+=1\n",
        "\n",
        "    else:\n",
        "        print(\"Not found in any tweet\")\n",
        "\n",
        "    final_tweets_id=[]\n",
        "    pos_idx = []\n",
        "    for p in ans:\n",
        "        held_for_now=filtered_Sentence[p].split()\n",
        "\n",
        "        if( held_for_now.index(str_to_process[0]) == (held_for_now.index(str_to_process[1])-1) ):\n",
        "            final_tweets_id.append(p)\n",
        "            pos_idx.append(len(final_tweets_id))\n",
        "            pos_idx.append(final_tweets_id)\n",
        "    \n",
        "    end=time.time()\n",
        "    time_taken=end-start \n",
        "\n",
        "    print(\"The phrase is present in tweet ids:\",pos_idx)\n",
        "    print(\"Time taken to fetch the phrase query: \",time_taken,\"seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-A92CoyZtjv",
        "outputId": "355db5ab-8614-478a-ef0d-96f6bf3acb80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The phrase is present in tweet ids: [1, [0]]\n",
            "Time taken to fetch the phrase query:  0.0 seconds\n"
          ]
        }
      ],
      "source": [
        "get_phrase_query(\"understand would\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Boolean Intersection Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_intersection_postings(word1, word2):\n",
        "    flag = False\n",
        "    start=time.time()\n",
        "    required = []\n",
        "    answer = {}\n",
        "    dictionary_items = postings.items()\n",
        "    for i in dictionary_items:\n",
        "        if(i[0] == word1):\n",
        "            required.append(i)\n",
        "        if(i[0] == word2):\n",
        "            required.append(i)\n",
        "        else:\n",
        "            continue\n",
        "    \n",
        "    indexes = []\n",
        "    list1 = []\n",
        "    list2 = []\n",
        "    \n",
        "    for i in required:\n",
        "        word, posting2 = i\n",
        "        frequency, index = posting2[0], posting2[1]\n",
        "        indexes.append(index)\n",
        "\n",
        "    list1, list2 = indexes[0], indexes[1]\n",
        "\n",
        "    list3 = [value for value in list1 if value in list2]\n",
        "    answer[word1+ \" AND \" + word2]= list(set(list3))\n",
        "    \n",
        "    end=time.time()\n",
        "    time_taken=end-start       #Time\n",
        "    \n",
        "    if len(list3):\n",
        "        print(answer)\n",
        "        print(\"Time taken to fetch (boolean query): \",time_taken,\"seconds\")\n",
        "    else:\n",
        "        print(\"No intersection possible\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'apologies AND help': [81]}\n",
            "Time taken to fetch (boolean query):  0.0 seconds\n"
          ]
        }
      ],
      "source": [
        "get_intersection_postings(\"apologies\",\"help\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Boolean Union Query "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_union_postings(word1, word2):\n",
        "    flag = False\n",
        "    start=time.time()\n",
        "    required = []\n",
        "    answer = {}\n",
        "    dictionary_items = postings.items()\n",
        "    for i in dictionary_items:\n",
        "      if(i[0] == word1):\n",
        "          required.append(i)\n",
        "      if(i[0] == word2):\n",
        "          required.append(i)\n",
        "      else:\n",
        "        continue\n",
        "    indexes = []\n",
        "    list1 = []\n",
        "    list2 = []\n",
        "    for i in required:\n",
        "      word, posting2 = i\n",
        "      frequency, index = posting2[0], posting2[1]\n",
        "      indexes.append(index)\n",
        "\n",
        "    list1, list2 = indexes[0], indexes[1]\n",
        "      \n",
        "    list3 = list1 + list2 \n",
        "    answer[word1+ \" OR \" + word2]= list(set(list3))\n",
        "    end=time.time()\n",
        "    time_taken=end-start     \n",
        "    if len(list3):\n",
        "      print(answer)\n",
        "      print(\"Time taken to fetch (boolean query): \",time_taken,\"seconds\")\n",
        "    else:\n",
        "      print(\"No Union possible\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'apologies OR help': [35, 99, 76, 81, 24, 28, 61, 31]}\n",
            "Time taken to fetch (boolean query):  0.0 seconds\n"
          ]
        }
      ],
      "source": [
        "get_union_postings(\"apologies\",\"help\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Similarity Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-PyCVVxNZtj1"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "wscWR03hZtj2"
      },
      "outputs": [],
      "source": [
        "def similarity(inv_index):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(lemma_word)\n",
        "\n",
        "    cosine_similarities = cosine_similarity(tfidf_matrix)\n",
        "    sim = {}\n",
        "    document_index = inv_index\n",
        "    # print the most similar documents and their cosine similarity scores\n",
        "    for i in range(len(document_index)):\n",
        "        similar_document_indices = cosine_similarities[document_index[i]].argsort()[:-5:-1]\n",
        "        # print(f\"Most similar documents to document {document_index[i]}:\")\n",
        "        for index in similar_document_indices[1:]:\n",
        "            print(f\"- Document {index}: similarity score = {cosine_similarities[document_index[i]][index]}\")\n",
        "            print(lemma_word[index])\n",
        "            sim[lemma_word[index]] = cosine_similarities[document_index[i]][index]\n",
        "    global ranked\n",
        "    ranked = {k: sim[k] for k in sorted(sim)}\n",
        "    print(\"---------------------------------------------------------------------------\")\n",
        "    print(\"The documents after being ranked are\")\n",
        "    for key in ranked.keys():\n",
        "        print(key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "vPmntuipZtj5"
      },
      "outputs": [],
      "source": [
        "def search_similiar_documents():\n",
        "    querry = str(input(\"Enter the word you want to search for: \"))\n",
        "    print(f\"The documents similar to '{querry}' has been found in: \")\n",
        "    inv_index = inverted_index[querry]\n",
        "    similarity(inv_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElOR1dcFZtj7",
        "outputId": "8314eb5e-ccdd-4e67-dc15-73432b0766e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The documents similar to 'apologies' has been found in: \n",
            "- Document 81: similarity score = 0.20566293021601065\n",
            "apologies sent dm help becky\n",
            "- Document 75: similarity score = 0.16080911068964043\n",
            "happy halloween since old trick treat look forward 3 booritos got mine earlier\n",
            "- Document 65: similarity score = 0.1437668254778442\n",
            "guac happy great experience becky\n",
            "- Document 61: similarity score = 0.27393194672695026\n",
            "sorry please tell us help becky\n",
            "- Document 28: similarity score = 0.24012822935206632\n",
            "help arrived sorry see trouble help hsb\n",
            "- Document 99: similarity score = 0.20986492269189536\n",
            "get help already\n",
            "---------------------------------------------------------------------------\n",
            "The documents after being ranked are\n",
            "apologies sent dm help becky\n",
            "get help already\n",
            "guac happy great experience becky\n",
            "happy halloween since old trick treat look forward 3 booritos got mine earlier\n",
            "help arrived sorry see trouble help hsb\n",
            "sorry please tell us help becky\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  search_similiar_documents()\n",
        "except:\n",
        "  print(\"No documents\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wildcard Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSGJanUCsfr4",
        "outputId": "92bd4a33-d886-4693-8dc7-79ce1d7f8ae9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Results match:\n",
            "information incorrect jk\n",
            "department part corporate office particular area gone format unawa\n",
            "spectrum correct way via ocs account takeover email consent form need done local office\n",
            "spectrum incorrect information form front faxed maybe need maintain date information\n",
            "information pertaining account assumption correct need done local outlet wit\n",
            "actually broken link sent incorrect information\n",
            "happy halloween since old trick treat look forward 3 booritos got mine earlier\n",
            "thank resolving issue quickly best fanforlife\n"
          ]
        }
      ],
      "source": [
        "# Wildcard query\n",
        "import re\n",
        "\n",
        "# Add or remove the words in this list to vary the results\n",
        "wordlist = lemma_word\n",
        "wild = input(\"Enter the wildcard query to be searched for: \")\n",
        "\n",
        "print(\"\\nResults match:\")\n",
        "for word in wordlist:\n",
        "        # The .+ symbol is used in place of * symbol\n",
        "        if re.search(wild+'.+', word) or re.search(wild+'.', word): \n",
        "                print (word)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptuZ7k0wzc-A",
        "outputId": "2b82c01b-98a3-4837-da19-30e58ad5627b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of non alpha-numeric characters in the corpus: \n",
            "684\n"
          ]
        }
      ],
      "source": [
        "patterns= [r'\\W+']\n",
        "phrase = str(lemma_word)\n",
        "\n",
        "print(\"Number of non alpha-numeric characters in the corpus: \")\n",
        "for p in patterns:\n",
        "    match= re.findall(p, phrase)\n",
        "    print(len(match))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Relevance Feedback and Re ranking "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "def relevance_feedback(rel_word):\n",
        "    print(\"The documents after relevnce feedback is\")\n",
        "    inv_index = inverted_index[word]\n",
        "    similarity(inv_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The documents after relevnce feedback is\n",
            "- Document 61: similarity score = 0.3888598208575087\n",
            "sorry please tell us help becky\n",
            "- Document 99: similarity score = 0.2849917144592756\n",
            "get help already\n",
            "- Document 81: similarity score = 0.24012822935206632\n",
            "apologies sent dm help becky\n",
            "- Document 6: similarity score = 0.5705909047816624\n",
            "worst customer service\n",
            "- Document 61: similarity score = 0.21611304132574524\n",
            "sorry please tell us help becky\n",
            "- Document 25: similarity score = 0.19909642745461265\n",
            "yo spectrum customer service reps super nice imma start trippin get service going\n",
            "- Document 28: similarity score = 0.18701828103660634\n",
            "help arrived sorry see trouble help hsb\n",
            "- Document 87: similarity score = 0.17088803753286003\n",
            "incredibly concerning please provide details investigate becky\n",
            "- Document 99: similarity score = 0.16344840920046044\n",
            "get help already\n",
            "- Document 69: similarity score = 0.5616394411955679\n",
            "incredibly concerning please tell us becky\n",
            "- Document 28: similarity score = 0.3888598208575087\n",
            "help arrived sorry see trouble help hsb\n",
            "- Document 81: similarity score = 0.27393194672695026\n",
            "apologies sent dm help becky\n",
            "- Document 11: similarity score = 0.2199622582877821\n",
            "h definitely like work long experiencing issue aa\n",
            "- Document 82: similarity score = 0.20150634193316508\n",
            "tried work rude\n",
            "- Document 81: similarity score = 0.19718909355578115\n",
            "apologies sent dm help becky\n",
            "- Document 61: similarity score = 0.27393194672695026\n",
            "sorry please tell us help becky\n",
            "- Document 28: similarity score = 0.24012822935206632\n",
            "help arrived sorry see trouble help hsb\n",
            "- Document 99: similarity score = 0.20986492269189536\n",
            "get help already\n",
            "- Document 28: similarity score = 0.2849917144592756\n",
            "help arrived sorry see trouble help hsb\n",
            "- Document 63: similarity score = 0.2286986084135601\n",
            "hopefully get point becky\n",
            "- Document 81: similarity score = 0.20986492269189536\n",
            "apologies sent dm help becky\n",
            "---------------------------------------------------------------------------\n",
            "The documents after being ranked are\n",
            "apologies sent dm help becky\n",
            "get help already\n",
            "h definitely like work long experiencing issue aa\n",
            "help arrived sorry see trouble help hsb\n",
            "hopefully get point becky\n",
            "incredibly concerning please provide details investigate becky\n",
            "incredibly concerning please tell us becky\n",
            "sorry please tell us help becky\n",
            "tried work rude\n",
            "worst customer service\n",
            "yo spectrum customer service reps super nice imma start trippin get service going\n"
          ]
        }
      ],
      "source": [
        "word = str(input(\"Enter the words you found relevent: \"))\n",
        "relevance_feedback(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
